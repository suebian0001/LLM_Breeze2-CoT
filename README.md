大型語言模型（LLM）微調對多跳推理能力的影響研究
專案簡介
在大型語言模型（LLM）的快速發展中，如何提升其處理複雜、多步驟的「多跳推理」任務是一個核心挑戰。我們發現，原生模型雖然知識豐富，但在面對需要邏輯推演的問題時，常會出現「假性推理」的現象，也就是答案看似正確，但推導過程卻是錯誤的。

這個專案正是為了探討兩種微調方法對模型推理能力的影響：

微調答案模型（FT-AO）：只提供正確答案進行微調。

微調思維鏈模型（FT-CoT）：提供包含完整推理過程的數據進行微調。

我們的研究核心發現是：CoT 微調不僅能顯著提高模型的答案準確率，更能賦予其真正的多步驟推理能力，讓模型能有條理地解決複雜問題，而不僅僅是記住答案。

專案架構
/llm-finetuning
├── /data
│   ├── /dataset
│   │   ├── train_chatml.jsonl
│   │   ├── train_chatml_cot.jsonl
│   │   ├── val_chatml.jsonl
│   │   └── test_chatml.jsonl
├── /results
│   ├── ft_ao_outputs_02.jsonl
│   ├── ft_cot_outputs_02.jsonl
│   └── base_model_outputs_02.jsonl
├── /notebooks
│   └── ...
├── README.md
└── requirements.txt

執行步驟
環境設定
首先，請確保你的環境已經安裝所有必要的 Python 套件。

pip install -r requirements.txt

接著，確認你的環境已配置適當的 GPU 支援（如 CUDA），這對於模型訓練和推論至關重要。

資料集準備
你的原始訓練與測試資料集已整理並放在 data/dataset 資料夾中。

模型微調
使用 train.ipynb 筆記本中的程式碼，分別對模型進行 FT-AO 和 FT-CoT 微調。請務必確認筆記本中的檔案路徑已設定正確。

模型評估與輸出
執行 evaluate.ipynb 筆記本中的程式碼，對原生模型、FT-AO 和 FT-CoT 模型進行性能評估。程式碼將會自動產生三份輸出檔案，並儲存在 results 資料夾中。

結果分析
你可以參考這份 README 提供的結論，或利用自己的分析腳本來比較三種模型的輸出，深入挖掘其表現差異。

結果與結論
原生模型：儘管具備強大的知識，但其表現出「假性推理」，答案往往籠統且缺乏邏輯支持，因此準確率最低。

微調 AO 模型：透過直接學習答案，模型的準確度大幅提升。這證明了微調在強化特定任務表現上的有效性，但我們發現其推理能力並未顯著提升。

微調 CoT 模型：在所有模型中表現最佳。其高準確率（>98%）和清晰的多步驟推理過程，有力證明了 CoT 微調能賦予模型真正的推理能力。

未來工作
探索 CoT 微調在不同領域（如數學、科學）的應用效果。

研究如何自動評估 LLM 的推理過程，而不僅僅是最終答案的正確性。