{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a0a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "分詞器已成功載入！\n"
     ]
    }
   ],
   "source": [
    "# cell 1 — 參數、路徑與基本設定\n",
    "\n",
    "import os, json, random, re, unicodedata\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, TrainingArguments, GenerationConfig,\n",
    "    AutoModelForCausalLM, AutoModel\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "import torch.nn as nn\n",
    "\n",
    "# 固定種子\n",
    "torch.manual_seed(42); random.seed(42)\n",
    "\n",
    "\n",
    "MODEL_NAME = \"MediaTek-Research/Llama-Breeze2-3B-Instruct-v0_1\"\n",
    "\n",
    "cot_train_data_file = r\"./0801/train_chatml_cot.jsonl\"\n",
    "ao_train_data_file  = r\"./0801/train_chatml.jsonl\"\n",
    "val_data_file       = r\"./0801/val_chatml.jsonl\"\n",
    "test_data_file      = r\"./0801/test_chatml.jsonl\"\n",
    "\n",
    "# 輸出\n",
    "OUTPUT_DIR_COT = \"./breeze2-lora-cot-02\"\n",
    "OUTPUT_DIR_AO  = \"./breeze2-lora-ao-02\"\n",
    "os.makedirs(OUTPUT_DIR_COT, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_AO,  exist_ok=True)\n",
    "os.makedirs(\"results\",      exist_ok=True)\n",
    "\n",
    "# 超參\n",
    "per_device_train_batch_size = 1\n",
    "gradient_accumulation_steps = 16\n",
    "num_train_epochs = 20\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.05\n",
    "warmup_ratio = 0.08\n",
    "max_grad_norm = 0.5\n",
    "logging_steps = 20\n",
    "eval_steps = 200\n",
    "save_steps = 200\n",
    "max_seq_length = 1024\n",
    "max_new_tokens = 1024  # 評估/存輸出\n",
    "\n",
    "# 生成設定\n",
    "gen_cfg = GenerationConfig(\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    do_sample=False,         \n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    "    repetition_penalty=1.05,\n",
    ")\n",
    "\n",
    "# 提示詞\n",
    "system_prompt_cot = (\n",
    "    \"你是一個歷史學家，請你針對問題在腦中進行詳細的邏輯推理。你的輸出必須包含完整的推理過程和最終答案。格式為：推理過程：\\[你的完整推理過程\\]最終答案：\\[你的最終結論\\]\"\n",
    ")\n",
    "system_prompt_ao  = (\n",
    "    \"你是一個歷史學家。請針對問題，直接給出最終答案。格式為：最終答案：\\[你的最終結論\\]\"\n",
    ")\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.truncation_side = \"left\"\n",
    "tokenizer.img_context_token_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f93609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention2 is not installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: 取得文字 LLM = LlamaForCausalLM\n"
     ]
    }
   ],
   "source": [
    "# cell 2 — 載入 Breeze2 wrapper → 抽出 language_model\n",
    "\n",
    "# 按模型卡示例設置 img_context_token_id（對 wrapper 友善）\n",
    "IMG_CTX_ID = 128212\n",
    "\n",
    "# 只用官方 wrapper 來載入，避免 AutoConfig 對 'internvl_chat' 的直載問題\n",
    "wrap = AutoModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=(torch.float16 if torch.cuda.is_available() else torch.float32),\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=None,\n",
    "    img_context_token_id=IMG_CTX_ID,\n",
    ").eval().to(DEVICE)\n",
    "\n",
    "# 抽出純文字 LLM（這個才交給 LoRA/TRL）\n",
    "if hasattr(wrap, \"language_model\"):\n",
    "    base_model = wrap.language_model\n",
    "else:\n",
    "    for cand in (\"llm\", \"text_model\", \"lm\", \"model\"):\n",
    "        if hasattr(wrap, cand):\n",
    "            base_model = getattr(wrap, cand)\n",
    "            break\n",
    "    else:\n",
    "        raise RuntimeError(\"找不到文字 LLM 子模組（language_model/llm/text_model/lm/model）。\")\n",
    "\n",
    "base_model.to(DEVICE).eval()\n",
    "print(\"OK: 取得文字 LLM =\", type(base_model).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7c190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3 — 將 ChatML 展平成純文字樣本（dataset_text_field='text' 用）\n",
    "\n",
    "SYS_FALLBACK = \"請在腦中逐步推理，但最終只輸出一行：最終答案：XXXX\"\n",
    "\n",
    "def formatting_prompts_func(batch):\n",
    "    outs = []\n",
    "    for msgs in batch[\"messages\"]:\n",
    "        m = msgs\n",
    "        if not m or m[0].get(\"role\") != \"system\":\n",
    "            m = [{\"role\":\"system\",\"content\": SYS_FALLBACK}] + m\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            m, tokenize=False, add_generation_prompt=False\n",
    "        )\n",
    "        outs.append(text)\n",
    "    return {\"text\": outs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4 — LoRA\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=\"all-linear\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "def build_lora_model():\n",
    "    m = get_peft_model(base_model, lora_config)\n",
    "    m.print_trainable_parameters()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1573d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5 — Logging callback\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CustomLoggingCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.logs = defaultdict(list)\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if getattr(state, \"is_local_process_zero\", True):\n",
    "            if logs is None: return\n",
    "            if \"loss\" in logs:\n",
    "                self.logs[\"train_loss\"].append(logs[\"loss\"])\n",
    "            if \"eval_loss\" in logs:\n",
    "                self.logs[\"eval_loss\"].append(logs[\"eval_loss\"])\n",
    "\n",
    "def plot_losses(logs, title, output_path):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if logs['train_loss']:\n",
    "        plt.plot(logs['train_loss'], label='Training Loss')\n",
    "    if logs['eval_loss']:\n",
    "        gap = max(1, len(logs['train_loss']) // max(1, len(logs['eval_loss'])))\n",
    "        xs = list(range(0, gap*len(logs['eval_loss']), gap))\n",
    "        plt.plot(xs, logs['eval_loss'], 'o-', label='Validation Loss')\n",
    "    plt.title(title); plt.xlabel('Training Steps'); plt.ylabel('Loss')\n",
    "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150)\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6 — 單次訓練函式（CoT / AO 都用）\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "def train_and_save_model(train_file, val_file, output_dir, model_type):\n",
    "    print(f\"\\n=== 開始訓練 {model_type} 模型（_02） ===\")\n",
    "\n",
    "    # 重新掛一個新的 LoRA（避免重複疊 adapter）\n",
    "    peft_model = build_lora_model()\n",
    "\n",
    "    # 讀資料並轉為純文字\n",
    "    train_ds = load_dataset(\"json\", data_files={\"train\": train_file}, split=\"train\")\n",
    "    val_ds = load_dataset(\"json\", data_files={\"validation\": val_file}, split=\"validation\")\n",
    "    train_text = train_ds.map(formatting_prompts_func, batched=True)\n",
    "    val_text = val_ds.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "    cb = CustomLoggingCallback()\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        logging_steps=logging_steps,\n",
    "        eval_steps=eval_steps,\n",
    "        save_steps=save_steps,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True,\n",
    "        fp16=True,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=peft_model,\n",
    "        tokenizer=tokenizer,\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        packing=True,\n",
    "        args=args,\n",
    "        train_dataset=train_text,\n",
    "        eval_dataset=val_text,\n",
    "        callbacks=[cb],\n",
    "    )\n",
    "\n",
    "    # 判斷是否從檢查點恢復\n",
    "    # 檢查 output_dir 是否存在，且裡面是否有 checkpoint 檔案\n",
    "    checkpoint_dirs = glob.glob(os.path.join(output_dir, \"checkpoint-*\"))\n",
    "    if len(checkpoint_dirs) > 0:\n",
    "        print(f\"在 {output_dir} 找到檢查點，從上一次訓練繼續...\")\n",
    "        trainer.train(resume_from_checkpoint=True)\n",
    "    else:\n",
    "        print(f\"在 {output_dir} 沒有找到檢查點，從頭開始訓練...\")\n",
    "        trainer.train()\n",
    "\n",
    "    trainer.save_model(output_dir)\n",
    "\n",
    "    plot_losses(cb.logs, f\"{model_type} Training & Validation Loss\", f\"results/{model_type.lower()}_loss_02.png\")\n",
    "\n",
    "    # 合併 LoRA → 單一 LLM（純文字）\n",
    "    merged = trainer.model.merge_and_unload()\n",
    "    merged_dir = os.path.join(output_dir, \"final_02\")\n",
    "    os.makedirs(merged_dir, exist_ok=True)\n",
    "    merged.save_pretrained(merged_dir)\n",
    "    tokenizer.save_pretrained(merged_dir)\n",
    "    print(f\"訓練完成！最終模型已保存於 {merged_dir}\")\n",
    "\n",
    "    # 釋放\n",
    "    del trainer, peft_model, merged\n",
    "    torch.cuda.empty_cache()\n",
    "    return merged_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02533151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 開始訓練 CoT 模型（_02） ===\n",
      "trainable params: 24,313,856 || all params: 3,631,066,112 || trainable%: 0.6696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, packing. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:192: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:413: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 ./breeze2-lora-cot-02 找到檢查點，從上一次訓練繼續...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\transformers\\trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "  0%|          | 0/4480 [00:00<?, ?it/s]\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\peft\\utils\\save_and_load.py:218: UserWarning: Could not find a config file in /mnt/shared/tp1-user/training/outputs/BreezeTinyInstruct_v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 0.2485, 'train_samples_per_second': 288712.248, 'train_steps_per_second': 18029.424, 'train_loss': 0.0, 'epoch': 19.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_28524\\1138968316.py:27: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(); plt.grid(True); plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 圖表已保存到 results/cot_loss_02.png\n",
      "訓練完成！最終模型已保存於 ./breeze2-lora-cot-02\\final_02\n",
      "\n",
      "=== 開始訓練 AO 模型（_02） ===\n",
      "trainable params: 24,313,856 || all params: 3,631,066,112 || trainable%: 0.6696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, packing. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:192: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:413: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 ./breeze2-lora-ao-02 找到檢查點，從上一次訓練繼續...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\transformers\\trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "  0%|          | 0/1160 [00:00<?, ?it/s]\n",
      "c:\\Users\\user\\Desktop\\0801\\.venv\\lib\\site-packages\\peft\\utils\\save_and_load.py:218: UserWarning: Could not find a config file in /mnt/shared/tp1-user/training/outputs/BreezeTinyInstruct_v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 0.4075, 'train_samples_per_second': 45982.427, 'train_steps_per_second': 2846.298, 'train_loss': 0.0, 'epoch': 19.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_28524\\1138968316.py:27: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(); plt.grid(True); plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 圖表已保存到 results/ao_loss_02.png\n",
      "訓練完成！最終模型已保存於 ./breeze2-lora-ao-02\\final_02\n",
      "兩個模型皆已完成訓練並合併存檔。\n"
     ]
    }
   ],
   "source": [
    "# cell 7 — 執行訓練（CoT / AO）\n",
    "\n",
    "merged_dir_cot_02 = train_and_save_model(cot_train_data_file, val_data_file, OUTPUT_DIR_COT, \"CoT\")\n",
    "merged_dir_ao_02  = train_and_save_model(ao_train_data_file,  val_data_file, OUTPUT_DIR_AO,  \"AO\")\n",
    "print(\"完成訓練。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674585a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 載入並評估原生模型（使用原始提示）===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.64s/it]\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始保存 base 模型輸出到 results/base_model_outputs_02.jsonl ...\n",
      "完成！輸出已保存到 results/base_model_outputs_02.jsonl\n",
      "\n",
      "=== 載入並評估 CoT 模型（使用 COT 提示）===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始保存 cot 模型輸出到 results/ft_cot_outputs_02.jsonl ...\n",
      "完成！輸出已保存到 results/ft_cot_outputs_02.jsonl\n",
      "\n",
      "=== 載入並評估 AO 模型（使用 AO 提示）===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始保存 ao 模型輸出到 results/ft_ao_outputs_02.jsonl ...\n",
      "完成！輸出已保存到 results/ft_ao_outputs_02.jsonl\n",
      "\n",
      "所有模型的評估已完成。\n"
     ]
    }
   ],
   "source": [
    "# cell 8 — 載入合併後模型並評估 / 輸出（_02）\n",
    "\n",
    "# 引入必要的函式庫\n",
    "import os, json, gc\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModel, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "# 推論設定\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    do_sample=True, temperature=0.01, top_p=0.01,\n",
    "    repetition_penalty=1.1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "def generate_prompt(question, model_type):\n",
    "    if model_type == \"base\":\n",
    "        messages = [{\"role\": \"user\", \"content\": question}]\n",
    "        return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    system_p = system_prompt_cot if model_type == \"cot\" else system_prompt_ao\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_p},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer(model, tokenizer, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False).to(model.device)\n",
    "    outputs = model.generate(**inputs, generation_config=generation_config, pad_token_id=tokenizer.eos_token_id)\n",
    "    output_str = tokenizer.decode(outputs[0])\n",
    "    return output_str.replace(prompt, \"\")\n",
    "\n",
    "test_dataset = load_dataset(\"json\", data_files={\"test\": test_data_file}, split=\"test\")\n",
    "\n",
    "def save_outputs(model, tokenizer, dataset, file_path, model_type):\n",
    "    print(f\"開始保存 {model_type} 模型輸出到 {file_path} ...\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ex in dataset:\n",
    "            user_message = ex[\"messages\"][1][\"content\"]\n",
    "            prompt = generate_prompt(user_message, model_type)\n",
    "            raw_output = infer(model, tokenizer, prompt)\n",
    "            rec = {\n",
    "                \"question\": user_message,\n",
    "                \"raw_output\": raw_output,\n",
    "                \"target\": ex[\"messages\"][2][\"content\"],\n",
    "            }\n",
    "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"完成！輸出已保存到 {file_path}\")\n",
    "\n",
    "# 設定輸出檔案路徑\n",
    "BASE_MODEL_OUTPUTS = \"results/base_model_outputs_02.jsonl\"\n",
    "FT_COT_OUTPUTS = \"results/ft_cot_outputs_02.jsonl\"\n",
    "FT_AO_OUTPUTS  = \"results/ft_ao_outputs_02.jsonl\"\n",
    "\n",
    "# 1) 載入並評估原生模型 \n",
    "print(\"=== 載入並評估原生模型（使用原始提示）===\")\n",
    "try:\n",
    "    wrap_base = AutoModel.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=(torch.float16 if torch.cuda.is_available() else torch.float32),\n",
    "        low_cpu_mem_usage=True,\n",
    "        device_map=\"auto\",\n",
    "        img_context_token_id=128212,\n",
    "    ).eval()\n",
    "    if hasattr(wrap_base, \"language_model\"):\n",
    "        base_model_for_eval = wrap_base.language_model\n",
    "    else:\n",
    "        for cand in (\"llm\", \"text_model\", \"lm\", \"model\"):\n",
    "            if hasattr(wrap_base, cand):\n",
    "                base_model_for_eval = getattr(wrap_base, cand)\n",
    "                break\n",
    "        else:\n",
    "            raise RuntimeError(\"找不到文字 LLM 子模組。\")\n",
    "    base_model_for_eval.to(DEVICE).eval()\n",
    "    save_outputs(base_model_for_eval, tokenizer, test_dataset, BASE_MODEL_OUTPUTS, \"base\")\n",
    "except Exception as e:\n",
    "    print(f\"原生模型載入或評估失敗，錯誤：{e}\")\n",
    "finally:\n",
    "    try:\n",
    "        del base_model_for_eval, wrap_base\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "# 2) 載入並評估 CoT 微調後模型 \n",
    "print(\"\\n=== 載入並評估 CoT 模型（使用 COT 提示）===\")\n",
    "try:\n",
    "    merged_model_cot = AutoModelForCausalLM.from_pretrained(\n",
    "        os.path.join(OUTPUT_DIR_COT, \"final_02\"),\n",
    "        torch_dtype=(torch.float16 if torch.cuda.is_available() else torch.float32),\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "    ).eval()\n",
    "    save_outputs(merged_model_cot, tokenizer, test_dataset, FT_COT_OUTPUTS, \"cot\")\n",
    "finally:\n",
    "    try:\n",
    "        del merged_model_cot\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "# 3) 載入並評估 AO 微調後模型 \n",
    "print(\"\\n=== 載入並評估 AO 模型（使用 AO 提示）===\")\n",
    "try:\n",
    "    merged_model_ao = AutoModelForCausalLM.from_pretrained(\n",
    "        os.path.join(OUTPUT_DIR_AO, \"final_02\"),\n",
    "        torch_dtype=(torch.float16 if torch.cuda.is_available() else torch.float32),\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "    ).eval()\n",
    "    save_outputs(merged_model_ao, tokenizer, test_dataset, FT_AO_OUTPUTS, \"ao\")\n",
    "finally:\n",
    "    try:\n",
    "        del merged_model_ao\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "print(\"\\n所有模型的評估已完成。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
