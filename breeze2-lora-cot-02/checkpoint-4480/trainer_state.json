{
  "best_metric": 0.7920883893966675,
  "best_model_checkpoint": "./breeze2-lora-cot-02\\checkpoint-1200",
  "epoch": 19.994703094507944,
  "eval_steps": 200,
  "global_step": 4480,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08921103986618344,
      "grad_norm": 11.19596004486084,
      "learning_rate": 1.0584958217270195e-06,
      "loss": 24.0806,
      "step": 20
    },
    {
      "epoch": 0.17842207973236687,
      "grad_norm": 11.052362442016602,
      "learning_rate": 2.116991643454039e-06,
      "loss": 23.8972,
      "step": 40
    },
    {
      "epoch": 0.2676331195985503,
      "grad_norm": 10.651281356811523,
      "learning_rate": 3.231197771587744e-06,
      "loss": 23.1105,
      "step": 60
    },
    {
      "epoch": 0.35684415946473375,
      "grad_norm": 9.672101974487305,
      "learning_rate": 4.345403899721449e-06,
      "loss": 21.8024,
      "step": 80
    },
    {
      "epoch": 0.4460551993309172,
      "grad_norm": 8.215085983276367,
      "learning_rate": 5.459610027855154e-06,
      "loss": 20.192,
      "step": 100
    },
    {
      "epoch": 0.5352662391971006,
      "grad_norm": 7.483219146728516,
      "learning_rate": 6.573816155988858e-06,
      "loss": 18.234,
      "step": 120
    },
    {
      "epoch": 0.6244772790632841,
      "grad_norm": 7.721985816955566,
      "learning_rate": 7.688022284122564e-06,
      "loss": 16.0432,
      "step": 140
    },
    {
      "epoch": 0.7136883189294675,
      "grad_norm": 6.1799397468566895,
      "learning_rate": 8.802228412256268e-06,
      "loss": 13.8454,
      "step": 160
    },
    {
      "epoch": 0.802899358795651,
      "grad_norm": 4.847464084625244,
      "learning_rate": 9.916434540389973e-06,
      "loss": 12.3592,
      "step": 180
    },
    {
      "epoch": 0.8921103986618344,
      "grad_norm": 4.736756801605225,
      "learning_rate": 1.1030640668523678e-05,
      "loss": 11.464,
      "step": 200
    },
    {
      "epoch": 0.8921103986618344,
      "eval_loss": 1.1002315282821655,
      "eval_runtime": 107.299,
      "eval_samples_per_second": 1.1,
      "eval_steps_per_second": 0.14,
      "step": 200
    },
    {
      "epoch": 0.9813214385280179,
      "grad_norm": 5.650788307189941,
      "learning_rate": 1.2144846796657384e-05,
      "loss": 11.0321,
      "step": 220
    },
    {
      "epoch": 1.0669082798996377,
      "grad_norm": 5.054001808166504,
      "learning_rate": 1.3259052924791087e-05,
      "loss": 10.3481,
      "step": 240
    },
    {
      "epoch": 1.156119319765821,
      "grad_norm": 5.39105224609375,
      "learning_rate": 1.4373259052924793e-05,
      "loss": 10.544,
      "step": 260
    },
    {
      "epoch": 1.2453303596320044,
      "grad_norm": 5.615518093109131,
      "learning_rate": 1.5487465181058498e-05,
      "loss": 10.2846,
      "step": 280
    },
    {
      "epoch": 1.3345413994981878,
      "grad_norm": 5.60059118270874,
      "learning_rate": 1.66016713091922e-05,
      "loss": 10.1951,
      "step": 300
    },
    {
      "epoch": 1.4237524393643715,
      "grad_norm": 5.777509689331055,
      "learning_rate": 1.7715877437325907e-05,
      "loss": 10.1067,
      "step": 320
    },
    {
      "epoch": 1.5129634792305549,
      "grad_norm": 6.033018589019775,
      "learning_rate": 1.883008356545961e-05,
      "loss": 9.969,
      "step": 340
    },
    {
      "epoch": 1.6021745190967382,
      "grad_norm": 6.4471755027771,
      "learning_rate": 1.9944289693593316e-05,
      "loss": 9.8921,
      "step": 360
    },
    {
      "epoch": 1.6913855589629216,
      "grad_norm": 6.563378810882568,
      "learning_rate": 1.990778937151177e-05,
      "loss": 9.6834,
      "step": 380
    },
    {
      "epoch": 1.780596598829105,
      "grad_norm": 6.793508052825928,
      "learning_rate": 1.9810725552050472e-05,
      "loss": 9.6734,
      "step": 400
    },
    {
      "epoch": 1.780596598829105,
      "eval_loss": 0.9557076692581177,
      "eval_runtime": 91.4462,
      "eval_samples_per_second": 1.29,
      "eval_steps_per_second": 0.164,
      "step": 400
    },
    {
      "epoch": 1.8698076386952884,
      "grad_norm": 6.521090507507324,
      "learning_rate": 1.971366173258918e-05,
      "loss": 9.5201,
      "step": 420
    },
    {
      "epoch": 1.9590186785614718,
      "grad_norm": 6.811248302459717,
      "learning_rate": 1.9616597913127883e-05,
      "loss": 9.3413,
      "step": 440
    },
    {
      "epoch": 2.044605519933092,
      "grad_norm": 6.765337944030762,
      "learning_rate": 1.951953409366659e-05,
      "loss": 8.7095,
      "step": 460
    },
    {
      "epoch": 2.1338165597992753,
      "grad_norm": 7.291633605957031,
      "learning_rate": 1.942247027420529e-05,
      "loss": 8.8137,
      "step": 480
    },
    {
      "epoch": 2.2230275996654587,
      "grad_norm": 7.576013565063477,
      "learning_rate": 1.9325406454743996e-05,
      "loss": 8.6684,
      "step": 500
    },
    {
      "epoch": 2.312238639531642,
      "grad_norm": 7.3567214012146,
      "learning_rate": 1.9228342635282698e-05,
      "loss": 8.657,
      "step": 520
    },
    {
      "epoch": 2.4014496793978255,
      "grad_norm": 7.256882190704346,
      "learning_rate": 1.9131278815821403e-05,
      "loss": 8.5391,
      "step": 540
    },
    {
      "epoch": 2.490660719264009,
      "grad_norm": 6.730197906494141,
      "learning_rate": 1.903421499636011e-05,
      "loss": 8.5322,
      "step": 560
    },
    {
      "epoch": 2.5798717591301923,
      "grad_norm": 7.096497058868408,
      "learning_rate": 1.893715117689881e-05,
      "loss": 8.4954,
      "step": 580
    },
    {
      "epoch": 2.6690827989963757,
      "grad_norm": 7.235616207122803,
      "learning_rate": 1.8840087357437516e-05,
      "loss": 8.4483,
      "step": 600
    },
    {
      "epoch": 2.6690827989963757,
      "eval_loss": 0.7993537187576294,
      "eval_runtime": 90.9089,
      "eval_samples_per_second": 1.298,
      "eval_steps_per_second": 0.165,
      "step": 600
    },
    {
      "epoch": 2.758293838862559,
      "grad_norm": 7.500016212463379,
      "learning_rate": 1.874302353797622e-05,
      "loss": 8.4765,
      "step": 620
    },
    {
      "epoch": 2.847504878728743,
      "grad_norm": 7.170412540435791,
      "learning_rate": 1.8645959718514927e-05,
      "loss": 8.4068,
      "step": 640
    },
    {
      "epoch": 2.936715918594926,
      "grad_norm": 7.86607551574707,
      "learning_rate": 1.854889589905363e-05,
      "loss": 8.4255,
      "step": 660
    },
    {
      "epoch": 3.022302759966546,
      "grad_norm": 7.627105712890625,
      "learning_rate": 1.8451832079592334e-05,
      "loss": 8.0893,
      "step": 680
    },
    {
      "epoch": 3.1115137998327294,
      "grad_norm": 8.72888469696045,
      "learning_rate": 1.8354768260131036e-05,
      "loss": 8.1877,
      "step": 700
    },
    {
      "epoch": 3.2007248396989127,
      "grad_norm": 7.709526538848877,
      "learning_rate": 1.8257704440669742e-05,
      "loss": 8.2226,
      "step": 720
    },
    {
      "epoch": 3.289935879565096,
      "grad_norm": 7.688032150268555,
      "learning_rate": 1.8160640621208444e-05,
      "loss": 8.2062,
      "step": 740
    },
    {
      "epoch": 3.3791469194312795,
      "grad_norm": 7.786442279815674,
      "learning_rate": 1.8063576801747153e-05,
      "loss": 8.2022,
      "step": 760
    },
    {
      "epoch": 3.468357959297463,
      "grad_norm": 7.635588645935059,
      "learning_rate": 1.7966512982285855e-05,
      "loss": 8.0819,
      "step": 780
    },
    {
      "epoch": 3.5575689991636468,
      "grad_norm": 8.193853378295898,
      "learning_rate": 1.786944916282456e-05,
      "loss": 8.1769,
      "step": 800
    },
    {
      "epoch": 3.5575689991636468,
      "eval_loss": 0.798060953617096,
      "eval_runtime": 88.904,
      "eval_samples_per_second": 1.327,
      "eval_steps_per_second": 0.169,
      "step": 800
    },
    {
      "epoch": 3.6601616950097573,
      "grad_norm": 8.21773624420166,
      "learning_rate": 1.7772385343363262e-05,
      "loss": 8.1404,
      "step": 820
    },
    {
      "epoch": 3.7493727348759407,
      "grad_norm": 8.165322303771973,
      "learning_rate": 1.7675321523901968e-05,
      "loss": 8.1703,
      "step": 840
    },
    {
      "epoch": 3.8385837747421245,
      "grad_norm": 8.079662322998047,
      "learning_rate": 1.757825770444067e-05,
      "loss": 7.9846,
      "step": 860
    },
    {
      "epoch": 3.927794814608308,
      "grad_norm": 8.05164909362793,
      "learning_rate": 1.7486047075952438e-05,
      "loss": 8.0035,
      "step": 880
    },
    {
      "epoch": 4.017842207973237,
      "grad_norm": 8.150070190429688,
      "learning_rate": 1.7388983256491144e-05,
      "loss": 8.073,
      "step": 900
    },
    {
      "epoch": 4.10705324783942,
      "grad_norm": 8.524641036987305,
      "learning_rate": 1.729191943702985e-05,
      "loss": 7.9287,
      "step": 920
    },
    {
      "epoch": 4.196264287705604,
      "grad_norm": 8.570629119873047,
      "learning_rate": 1.7194855617568555e-05,
      "loss": 7.9241,
      "step": 940
    },
    {
      "epoch": 4.285475327571787,
      "grad_norm": 8.92566204071045,
      "learning_rate": 1.7097791798107257e-05,
      "loss": 7.9384,
      "step": 960
    },
    {
      "epoch": 4.37468636743797,
      "grad_norm": 9.10096549987793,
      "learning_rate": 1.7005581169619025e-05,
      "loss": 8.0687,
      "step": 980
    },
    {
      "epoch": 4.463897407304154,
      "grad_norm": 8.728099822998047,
      "learning_rate": 1.690851735015773e-05,
      "loss": 7.8661,
      "step": 1000
    },
    {
      "epoch": 4.463897407304154,
      "eval_loss": 0.7959021925926208,
      "eval_runtime": 139.7333,
      "eval_samples_per_second": 0.844,
      "eval_steps_per_second": 0.107,
      "step": 1000
    },
    {
      "epoch": 4.553108447170337,
      "grad_norm": 9.236237525939941,
      "learning_rate": 1.6811453530696433e-05,
      "loss": 7.9274,
      "step": 1020
    },
    {
      "epoch": 4.642319487036521,
      "grad_norm": 9.027878761291504,
      "learning_rate": 1.6714389711235138e-05,
      "loss": 8.0125,
      "step": 1040
    },
    {
      "epoch": 4.731530526902704,
      "grad_norm": 8.827659606933594,
      "learning_rate": 1.6617325891773844e-05,
      "loss": 7.9389,
      "step": 1060
    },
    {
      "epoch": 4.820741566768888,
      "grad_norm": 9.383581161499023,
      "learning_rate": 1.652026207231255e-05,
      "loss": 7.952,
      "step": 1080
    },
    {
      "epoch": 4.909952606635071,
      "grad_norm": 8.23404312133789,
      "learning_rate": 1.642319825285125e-05,
      "loss": 7.931,
      "step": 1100
    },
    {
      "epoch": 4.9991636465012546,
      "grad_norm": 9.409006118774414,
      "learning_rate": 1.6326134433389956e-05,
      "loss": 7.969,
      "step": 1120
    },
    {
      "epoch": 5.084750487872874,
      "grad_norm": 8.956062316894531,
      "learning_rate": 1.622907061392866e-05,
      "loss": 7.4574,
      "step": 1140
    },
    {
      "epoch": 5.173961527739058,
      "grad_norm": 9.33293628692627,
      "learning_rate": 1.6132006794467364e-05,
      "loss": 7.7388,
      "step": 1160
    },
    {
      "epoch": 5.263172567605241,
      "grad_norm": 9.739751815795898,
      "learning_rate": 1.6034942975006066e-05,
      "loss": 7.8111,
      "step": 1180
    },
    {
      "epoch": 5.352383607471425,
      "grad_norm": 9.813477516174316,
      "learning_rate": 1.593787915554477e-05,
      "loss": 7.8822,
      "step": 1200
    },
    {
      "epoch": 5.352383607471425,
      "eval_loss": 0.7920883893966675,
      "eval_runtime": 91.2315,
      "eval_samples_per_second": 1.293,
      "eval_steps_per_second": 0.164,
      "step": 1200
    },
    {
      "epoch": 5.441594647337608,
      "grad_norm": 9.492679595947266,
      "learning_rate": 1.5840815336083477e-05,
      "loss": 7.7574,
      "step": 1220
    },
    {
      "epoch": 5.530805687203792,
      "grad_norm": 10.021957397460938,
      "learning_rate": 1.5743751516622182e-05,
      "loss": 7.7127,
      "step": 1240
    },
    {
      "epoch": 5.620016727069975,
      "grad_norm": 9.823246955871582,
      "learning_rate": 1.5646687697160884e-05,
      "loss": 7.8743,
      "step": 1260
    },
    {
      "epoch": 5.709227766936158,
      "grad_norm": 9.425872802734375,
      "learning_rate": 1.554962387769959e-05,
      "loss": 7.8305,
      "step": 1280
    },
    {
      "epoch": 5.798438806802341,
      "grad_norm": 8.922467231750488,
      "learning_rate": 1.545256005823829e-05,
      "loss": 7.6851,
      "step": 1300
    },
    {
      "epoch": 5.887649846668525,
      "grad_norm": 10.170653343200684,
      "learning_rate": 1.5355496238776997e-05,
      "loss": 7.7328,
      "step": 1320
    },
    {
      "epoch": 5.976860886534709,
      "grad_norm": 9.867154121398926,
      "learning_rate": 1.52584324193157e-05,
      "loss": 7.7892,
      "step": 1340
    },
    {
      "epoch": 6.062447727906329,
      "grad_norm": 10.063403129577637,
      "learning_rate": 1.5161368599854404e-05,
      "loss": 7.3505,
      "step": 1360
    },
    {
      "epoch": 6.151658767772512,
      "grad_norm": 9.645085334777832,
      "learning_rate": 1.5064304780393108e-05,
      "loss": 7.7055,
      "step": 1380
    },
    {
      "epoch": 6.2408698076386955,
      "grad_norm": 9.860559463500977,
      "learning_rate": 1.4967240960931815e-05,
      "loss": 7.5905,
      "step": 1400
    },
    {
      "epoch": 6.2408698076386955,
      "eval_loss": 0.8044290542602539,
      "eval_runtime": 92.2057,
      "eval_samples_per_second": 1.28,
      "eval_steps_per_second": 0.163,
      "step": 1400
    },
    {
      "epoch": 6.330080847504878,
      "grad_norm": 10.08891773223877,
      "learning_rate": 1.4870177141470519e-05,
      "loss": 7.6464,
      "step": 1420
    },
    {
      "epoch": 6.419291887371062,
      "grad_norm": 10.666189193725586,
      "learning_rate": 1.4773113322009222e-05,
      "loss": 7.6128,
      "step": 1440
    },
    {
      "epoch": 6.508502927237245,
      "grad_norm": 9.836633682250977,
      "learning_rate": 1.4676049502547926e-05,
      "loss": 7.7505,
      "step": 1460
    },
    {
      "epoch": 6.597713967103429,
      "grad_norm": 10.091484069824219,
      "learning_rate": 1.457898568308663e-05,
      "loss": 7.6642,
      "step": 1480
    },
    {
      "epoch": 6.686925006969613,
      "grad_norm": 10.201024055480957,
      "learning_rate": 1.4481921863625335e-05,
      "loss": 7.7176,
      "step": 1500
    },
    {
      "epoch": 6.776136046835796,
      "grad_norm": 10.064787864685059,
      "learning_rate": 1.4384858044164039e-05,
      "loss": 7.6017,
      "step": 1520
    },
    {
      "epoch": 6.86534708670198,
      "grad_norm": 10.421870231628418,
      "learning_rate": 1.4287794224702743e-05,
      "loss": 7.5809,
      "step": 1540
    },
    {
      "epoch": 6.954558126568163,
      "grad_norm": 11.148530960083008,
      "learning_rate": 1.4190730405241448e-05,
      "loss": 7.6256,
      "step": 1560
    },
    {
      "epoch": 7.040144967939782,
      "grad_norm": 9.954277992248535,
      "learning_rate": 1.4093666585780152e-05,
      "loss": 7.2331,
      "step": 1580
    },
    {
      "epoch": 7.129356007805966,
      "grad_norm": 10.030632972717285,
      "learning_rate": 1.3996602766318857e-05,
      "loss": 7.5946,
      "step": 1600
    },
    {
      "epoch": 7.129356007805966,
      "eval_loss": 0.792365312576294,
      "eval_runtime": 93.028,
      "eval_samples_per_second": 1.268,
      "eval_steps_per_second": 0.161,
      "step": 1600
    },
    {
      "epoch": 7.231948703652077,
      "grad_norm": 10.575948715209961,
      "learning_rate": 1.389953894685756e-05,
      "loss": 7.624,
      "step": 1620
    },
    {
      "epoch": 7.32115974351826,
      "grad_norm": 11.357396125793457,
      "learning_rate": 1.3802475127396265e-05,
      "loss": 7.5326,
      "step": 1640
    },
    {
      "epoch": 7.410370783384444,
      "grad_norm": 10.274396896362305,
      "learning_rate": 1.3705411307934968e-05,
      "loss": 7.5602,
      "step": 1660
    },
    {
      "epoch": 7.499581823250628,
      "grad_norm": 10.524989128112793,
      "learning_rate": 1.3608347488473672e-05,
      "loss": 7.5195,
      "step": 1680
    },
    {
      "epoch": 7.588792863116811,
      "grad_norm": 10.325797080993652,
      "learning_rate": 1.3511283669012376e-05,
      "loss": 7.5819,
      "step": 1700
    },
    {
      "epoch": 7.6780039029829945,
      "grad_norm": 10.824374198913574,
      "learning_rate": 1.341421984955108e-05,
      "loss": 7.5033,
      "step": 1720
    },
    {
      "epoch": 7.7672149428491775,
      "grad_norm": 10.900617599487305,
      "learning_rate": 1.332200922106285e-05,
      "loss": 7.5382,
      "step": 1740
    },
    {
      "epoch": 7.856425982715361,
      "grad_norm": 10.143677711486816,
      "learning_rate": 1.3224945401601554e-05,
      "loss": 7.3928,
      "step": 1760
    },
    {
      "epoch": 7.945637022581544,
      "grad_norm": 11.283127784729004,
      "learning_rate": 1.3127881582140259e-05,
      "loss": 7.4367,
      "step": 1780
    },
    {
      "epoch": 8.035684415946474,
      "grad_norm": 11.011401176452637,
      "learning_rate": 1.3030817762678963e-05,
      "loss": 7.5192,
      "step": 1800
    },
    {
      "epoch": 8.035684415946474,
      "eval_loss": 0.8053954839706421,
      "eval_runtime": 115.7156,
      "eval_samples_per_second": 1.02,
      "eval_steps_per_second": 0.13,
      "step": 1800
    },
    {
      "epoch": 8.124895455812657,
      "grad_norm": 11.60608196258545,
      "learning_rate": 1.2933753943217666e-05,
      "loss": 7.4444,
      "step": 1820
    },
    {
      "epoch": 8.21410649567884,
      "grad_norm": 11.761289596557617,
      "learning_rate": 1.283669012375637e-05,
      "loss": 7.5069,
      "step": 1840
    },
    {
      "epoch": 8.303317535545023,
      "grad_norm": 11.633318901062012,
      "learning_rate": 1.2739626304295074e-05,
      "loss": 7.4447,
      "step": 1860
    },
    {
      "epoch": 8.392528575411207,
      "grad_norm": 11.493978500366211,
      "learning_rate": 1.2642562484833781e-05,
      "loss": 7.4523,
      "step": 1880
    },
    {
      "epoch": 8.481739615277391,
      "grad_norm": 12.059699058532715,
      "learning_rate": 1.2545498665372485e-05,
      "loss": 7.4329,
      "step": 1900
    },
    {
      "epoch": 8.570950655143575,
      "grad_norm": 11.418183326721191,
      "learning_rate": 1.2448434845911188e-05,
      "loss": 7.4308,
      "step": 1920
    },
    {
      "epoch": 8.660161695009757,
      "grad_norm": 11.8814115524292,
      "learning_rate": 1.2351371026449892e-05,
      "loss": 7.3804,
      "step": 1940
    },
    {
      "epoch": 8.74937273487594,
      "grad_norm": 11.459392547607422,
      "learning_rate": 1.2254307206988596e-05,
      "loss": 7.4774,
      "step": 1960
    },
    {
      "epoch": 8.838583774742125,
      "grad_norm": 11.13077449798584,
      "learning_rate": 1.21572433875273e-05,
      "loss": 7.3985,
      "step": 1980
    },
    {
      "epoch": 8.927794814608308,
      "grad_norm": 11.87795352935791,
      "learning_rate": 1.2060179568066003e-05,
      "loss": 7.3944,
      "step": 2000
    },
    {
      "epoch": 8.927794814608308,
      "eval_loss": 0.8016936779022217,
      "eval_runtime": 67.7293,
      "eval_samples_per_second": 1.742,
      "eval_steps_per_second": 0.221,
      "step": 2000
    },
    {
      "epoch": 9.013381655979927,
      "grad_norm": 11.267000198364258,
      "learning_rate": 1.1963115748604708e-05,
      "loss": 7.1247,
      "step": 2020
    },
    {
      "epoch": 9.102592695846111,
      "grad_norm": 10.660813331604004,
      "learning_rate": 1.1866051929143412e-05,
      "loss": 7.2439,
      "step": 2040
    },
    {
      "epoch": 9.191803735712295,
      "grad_norm": 11.451896667480469,
      "learning_rate": 1.1768988109682118e-05,
      "loss": 7.3005,
      "step": 2060
    },
    {
      "epoch": 9.281014775578479,
      "grad_norm": 12.01237964630127,
      "learning_rate": 1.1671924290220821e-05,
      "loss": 7.3267,
      "step": 2080
    },
    {
      "epoch": 9.37022581544466,
      "grad_norm": 11.341575622558594,
      "learning_rate": 1.1574860470759525e-05,
      "loss": 7.2927,
      "step": 2100
    },
    {
      "epoch": 9.459436855310845,
      "grad_norm": 11.617199897766113,
      "learning_rate": 1.147779665129823e-05,
      "loss": 7.3884,
      "step": 2120
    },
    {
      "epoch": 9.548647895177028,
      "grad_norm": 11.941184997558594,
      "learning_rate": 1.1380732831836934e-05,
      "loss": 7.4071,
      "step": 2140
    },
    {
      "epoch": 9.637858935043212,
      "grad_norm": 12.072601318359375,
      "learning_rate": 1.1283669012375638e-05,
      "loss": 7.3369,
      "step": 2160
    },
    {
      "epoch": 9.727069974909394,
      "grad_norm": 11.655778884887695,
      "learning_rate": 1.1186605192914342e-05,
      "loss": 7.3919,
      "step": 2180
    },
    {
      "epoch": 9.816281014775578,
      "grad_norm": 11.855380058288574,
      "learning_rate": 1.1089541373453045e-05,
      "loss": 7.4041,
      "step": 2200
    },
    {
      "epoch": 9.816281014775578,
      "eval_loss": 0.8029975891113281,
      "eval_runtime": 67.6935,
      "eval_samples_per_second": 1.743,
      "eval_steps_per_second": 0.222,
      "step": 2200
    },
    {
      "epoch": 9.905492054641762,
      "grad_norm": 11.256773948669434,
      "learning_rate": 1.0992477553991749e-05,
      "loss": 7.3561,
      "step": 2220
    },
    {
      "epoch": 9.994703094507946,
      "grad_norm": 12.178630828857422,
      "learning_rate": 1.0895413734530456e-05,
      "loss": 7.3603,
      "step": 2240
    },
    {
      "epoch": 10.080289935879565,
      "grad_norm": 11.711578369140625,
      "learning_rate": 1.079834991506916e-05,
      "loss": 6.903,
      "step": 2260
    },
    {
      "epoch": 10.169500975745748,
      "grad_norm": 12.010244369506836,
      "learning_rate": 1.0701286095607863e-05,
      "loss": 7.2623,
      "step": 2280
    },
    {
      "epoch": 10.258712015611932,
      "grad_norm": 12.107317924499512,
      "learning_rate": 1.0604222276146567e-05,
      "loss": 7.2158,
      "step": 2300
    },
    {
      "epoch": 10.347923055478116,
      "grad_norm": 12.280413627624512,
      "learning_rate": 1.0507158456685271e-05,
      "loss": 7.3107,
      "step": 2320
    },
    {
      "epoch": 10.437134095344298,
      "grad_norm": 12.557034492492676,
      "learning_rate": 1.0410094637223975e-05,
      "loss": 7.2568,
      "step": 2340
    },
    {
      "epoch": 10.526345135210482,
      "grad_norm": 11.942159652709961,
      "learning_rate": 1.031303081776268e-05,
      "loss": 7.2008,
      "step": 2360
    },
    {
      "epoch": 10.615556175076666,
      "grad_norm": 12.487971305847168,
      "learning_rate": 1.0215966998301384e-05,
      "loss": 7.2977,
      "step": 2380
    },
    {
      "epoch": 10.70476721494285,
      "grad_norm": 12.617560386657715,
      "learning_rate": 1.0118903178840087e-05,
      "loss": 7.2668,
      "step": 2400
    },
    {
      "epoch": 10.70476721494285,
      "eval_loss": 0.8272688984870911,
      "eval_runtime": 67.7922,
      "eval_samples_per_second": 1.741,
      "eval_steps_per_second": 0.221,
      "step": 2400
    },
    {
      "epoch": 10.793978254809034,
      "grad_norm": 11.778060913085938,
      "learning_rate": 1.0021839359378793e-05,
      "loss": 7.283,
      "step": 2420
    },
    {
      "epoch": 10.883189294675216,
      "grad_norm": 12.346356391906738,
      "learning_rate": 9.924775539917496e-06,
      "loss": 7.393,
      "step": 2440
    },
    {
      "epoch": 10.9724003345414,
      "grad_norm": 12.230717658996582,
      "learning_rate": 9.827711720456202e-06,
      "loss": 7.2215,
      "step": 2460
    },
    {
      "epoch": 11.05798717591302,
      "grad_norm": 12.938966751098633,
      "learning_rate": 9.730647900994906e-06,
      "loss": 6.902,
      "step": 2480
    },
    {
      "epoch": 11.147198215779202,
      "grad_norm": 13.109365463256836,
      "learning_rate": 9.63358408153361e-06,
      "loss": 7.2511,
      "step": 2500
    },
    {
      "epoch": 11.236409255645386,
      "grad_norm": 13.406180381774902,
      "learning_rate": 9.536520262072313e-06,
      "loss": 7.1287,
      "step": 2520
    },
    {
      "epoch": 11.32562029551157,
      "grad_norm": 12.24344539642334,
      "learning_rate": 9.439456442611018e-06,
      "loss": 7.142,
      "step": 2540
    },
    {
      "epoch": 11.414831335377754,
      "grad_norm": 12.44963264465332,
      "learning_rate": 9.342392623149722e-06,
      "loss": 7.255,
      "step": 2560
    },
    {
      "epoch": 11.504042375243937,
      "grad_norm": 12.616951942443848,
      "learning_rate": 9.245328803688426e-06,
      "loss": 7.1811,
      "step": 2580
    },
    {
      "epoch": 11.59325341511012,
      "grad_norm": 12.38806438446045,
      "learning_rate": 9.14826498422713e-06,
      "loss": 7.2036,
      "step": 2600
    },
    {
      "epoch": 11.59325341511012,
      "eval_loss": 0.8210217356681824,
      "eval_runtime": 70.5446,
      "eval_samples_per_second": 1.673,
      "eval_steps_per_second": 0.213,
      "step": 2600
    },
    {
      "epoch": 11.682464454976303,
      "grad_norm": 12.708572387695312,
      "learning_rate": 9.051201164765833e-06,
      "loss": 7.2496,
      "step": 2620
    },
    {
      "epoch": 11.771675494842487,
      "grad_norm": 12.8258056640625,
      "learning_rate": 8.954137345304539e-06,
      "loss": 7.1649,
      "step": 2640
    },
    {
      "epoch": 11.860886534708671,
      "grad_norm": 12.743565559387207,
      "learning_rate": 8.857073525843242e-06,
      "loss": 7.1679,
      "step": 2660
    },
    {
      "epoch": 11.950097574574853,
      "grad_norm": 12.781517028808594,
      "learning_rate": 8.760009706381946e-06,
      "loss": 7.2607,
      "step": 2680
    },
    {
      "epoch": 12.035684415946474,
      "grad_norm": 13.152960777282715,
      "learning_rate": 8.662945886920651e-06,
      "loss": 6.8407,
      "step": 2700
    },
    {
      "epoch": 12.124895455812657,
      "grad_norm": 12.91721248626709,
      "learning_rate": 8.565882067459355e-06,
      "loss": 7.032,
      "step": 2720
    },
    {
      "epoch": 12.21410649567884,
      "grad_norm": 13.57444953918457,
      "learning_rate": 8.468818247998059e-06,
      "loss": 7.1964,
      "step": 2740
    },
    {
      "epoch": 12.303317535545023,
      "grad_norm": 13.182934761047363,
      "learning_rate": 8.371754428536764e-06,
      "loss": 7.1349,
      "step": 2760
    },
    {
      "epoch": 12.392528575411207,
      "grad_norm": 13.030329704284668,
      "learning_rate": 8.274690609075468e-06,
      "loss": 7.106,
      "step": 2780
    },
    {
      "epoch": 12.481739615277391,
      "grad_norm": 12.716280937194824,
      "learning_rate": 8.177626789614172e-06,
      "loss": 7.1203,
      "step": 2800
    },
    {
      "epoch": 12.481739615277391,
      "eval_loss": 0.8204049468040466,
      "eval_runtime": 70.3769,
      "eval_samples_per_second": 1.677,
      "eval_steps_per_second": 0.213,
      "step": 2800
    },
    {
      "epoch": 12.570950655143575,
      "grad_norm": 12.513395309448242,
      "learning_rate": 8.080562970152877e-06,
      "loss": 7.1586,
      "step": 2820
    },
    {
      "epoch": 12.660161695009757,
      "grad_norm": 13.011581420898438,
      "learning_rate": 7.98349915069158e-06,
      "loss": 7.0913,
      "step": 2840
    },
    {
      "epoch": 12.74937273487594,
      "grad_norm": 13.45820426940918,
      "learning_rate": 7.886435331230284e-06,
      "loss": 7.1643,
      "step": 2860
    },
    {
      "epoch": 12.838583774742125,
      "grad_norm": 13.59226131439209,
      "learning_rate": 7.789371511768988e-06,
      "loss": 7.1494,
      "step": 2880
    },
    {
      "epoch": 12.927794814608308,
      "grad_norm": 12.585257530212402,
      "learning_rate": 7.692307692307694e-06,
      "loss": 7.1289,
      "step": 2900
    },
    {
      "epoch": 13.013381655979927,
      "grad_norm": 12.967864036560059,
      "learning_rate": 7.595243872846397e-06,
      "loss": 6.8721,
      "step": 2920
    },
    {
      "epoch": 13.102592695846111,
      "grad_norm": 13.86051082611084,
      "learning_rate": 7.498180053385101e-06,
      "loss": 7.0119,
      "step": 2940
    },
    {
      "epoch": 13.191803735712295,
      "grad_norm": 13.353652954101562,
      "learning_rate": 7.4011162339238056e-06,
      "loss": 7.0198,
      "step": 2960
    },
    {
      "epoch": 13.281014775578479,
      "grad_norm": 13.7184476852417,
      "learning_rate": 7.30405241446251e-06,
      "loss": 7.0791,
      "step": 2980
    },
    {
      "epoch": 13.37022581544466,
      "grad_norm": 14.136478424072266,
      "learning_rate": 7.206988595001214e-06,
      "loss": 7.0734,
      "step": 3000
    },
    {
      "epoch": 13.37022581544466,
      "eval_loss": 0.8262887597084045,
      "eval_runtime": 70.7602,
      "eval_samples_per_second": 1.668,
      "eval_steps_per_second": 0.212,
      "step": 3000
    },
    {
      "epoch": 13.459436855310845,
      "grad_norm": 12.945704460144043,
      "learning_rate": 7.109924775539918e-06,
      "loss": 7.0735,
      "step": 3020
    },
    {
      "epoch": 13.548647895177028,
      "grad_norm": 13.713784217834473,
      "learning_rate": 7.012860956078622e-06,
      "loss": 7.0759,
      "step": 3040
    },
    {
      "epoch": 13.637858935043212,
      "grad_norm": 13.64100456237793,
      "learning_rate": 6.915797136617326e-06,
      "loss": 7.0513,
      "step": 3060
    },
    {
      "epoch": 13.727069974909394,
      "grad_norm": 14.051765441894531,
      "learning_rate": 6.818733317156031e-06,
      "loss": 7.0832,
      "step": 3080
    },
    {
      "epoch": 13.816281014775578,
      "grad_norm": 13.323165893554688,
      "learning_rate": 6.721669497694735e-06,
      "loss": 7.0919,
      "step": 3100
    },
    {
      "epoch": 13.905492054641762,
      "grad_norm": 13.448099136352539,
      "learning_rate": 6.624605678233439e-06,
      "loss": 7.0849,
      "step": 3120
    },
    {
      "epoch": 13.994703094507946,
      "grad_norm": 13.929081916809082,
      "learning_rate": 6.527541858772143e-06,
      "loss": 7.1572,
      "step": 3140
    },
    {
      "epoch": 14.080289935879565,
      "grad_norm": 13.23231029510498,
      "learning_rate": 6.430478039310848e-06,
      "loss": 6.7406,
      "step": 3160
    },
    {
      "epoch": 14.169500975745748,
      "grad_norm": 14.219159126281738,
      "learning_rate": 6.333414219849552e-06,
      "loss": 6.9693,
      "step": 3180
    },
    {
      "epoch": 14.258712015611932,
      "grad_norm": 13.837841987609863,
      "learning_rate": 6.236350400388256e-06,
      "loss": 6.9558,
      "step": 3200
    },
    {
      "epoch": 14.258712015611932,
      "eval_loss": 0.8442659378051758,
      "eval_runtime": 70.8021,
      "eval_samples_per_second": 1.667,
      "eval_steps_per_second": 0.212,
      "step": 3200
    },
    {
      "epoch": 14.347923055478116,
      "grad_norm": 13.38597583770752,
      "learning_rate": 6.13928658092696e-06,
      "loss": 6.9959,
      "step": 3220
    },
    {
      "epoch": 14.437134095344298,
      "grad_norm": 13.839259147644043,
      "learning_rate": 6.042222761465663e-06,
      "loss": 7.0043,
      "step": 3240
    },
    {
      "epoch": 14.526345135210482,
      "grad_norm": 14.163865089416504,
      "learning_rate": 5.945158942004369e-06,
      "loss": 7.0789,
      "step": 3260
    },
    {
      "epoch": 14.615556175076666,
      "grad_norm": 13.968276023864746,
      "learning_rate": 5.8480951225430725e-06,
      "loss": 6.9966,
      "step": 3280
    },
    {
      "epoch": 14.70476721494285,
      "grad_norm": 14.275175094604492,
      "learning_rate": 5.751031303081776e-06,
      "loss": 7.0135,
      "step": 3300
    },
    {
      "epoch": 14.793978254809034,
      "grad_norm": 14.490117073059082,
      "learning_rate": 5.653967483620481e-06,
      "loss": 7.067,
      "step": 3320
    },
    {
      "epoch": 14.883189294675216,
      "grad_norm": 13.690370559692383,
      "learning_rate": 5.556903664159185e-06,
      "loss": 7.0719,
      "step": 3340
    },
    {
      "epoch": 14.9724003345414,
      "grad_norm": 14.509655952453613,
      "learning_rate": 5.45983984469789e-06,
      "loss": 7.0432,
      "step": 3360
    },
    {
      "epoch": 15.05798717591302,
      "grad_norm": 14.68399715423584,
      "learning_rate": 5.3627760252365935e-06,
      "loss": 6.6775,
      "step": 3380
    },
    {
      "epoch": 15.147198215779202,
      "grad_norm": 13.715750694274902,
      "learning_rate": 5.265712205775297e-06,
      "loss": 6.9256,
      "step": 3400
    },
    {
      "epoch": 15.147198215779202,
      "eval_loss": 0.838226854801178,
      "eval_runtime": 71.4126,
      "eval_samples_per_second": 1.652,
      "eval_steps_per_second": 0.21,
      "step": 3400
    },
    {
      "epoch": 15.236409255645386,
      "grad_norm": 15.349533081054688,
      "learning_rate": 5.168648386314001e-06,
      "loss": 6.9839,
      "step": 3420
    },
    {
      "epoch": 15.32562029551157,
      "grad_norm": 13.670757293701172,
      "learning_rate": 5.071584566852706e-06,
      "loss": 6.9575,
      "step": 3440
    },
    {
      "epoch": 15.414831335377754,
      "grad_norm": 14.132278442382812,
      "learning_rate": 4.97452074739141e-06,
      "loss": 6.9226,
      "step": 3460
    },
    {
      "epoch": 15.504042375243937,
      "grad_norm": 14.08533000946045,
      "learning_rate": 4.877456927930115e-06,
      "loss": 7.0107,
      "step": 3480
    },
    {
      "epoch": 15.59325341511012,
      "grad_norm": 14.37075424194336,
      "learning_rate": 4.780393108468819e-06,
      "loss": 6.9856,
      "step": 3500
    },
    {
      "epoch": 15.682464454976303,
      "grad_norm": 14.718091011047363,
      "learning_rate": 4.683329289007523e-06,
      "loss": 7.0056,
      "step": 3520
    },
    {
      "epoch": 15.771675494842487,
      "grad_norm": 14.260886192321777,
      "learning_rate": 4.5862654695462274e-06,
      "loss": 7.0141,
      "step": 3540
    },
    {
      "epoch": 15.860886534708671,
      "grad_norm": 13.95159912109375,
      "learning_rate": 4.489201650084931e-06,
      "loss": 6.9436,
      "step": 3560
    },
    {
      "epoch": 15.950097574574853,
      "grad_norm": 13.874156951904297,
      "learning_rate": 4.392137830623636e-06,
      "loss": 6.958,
      "step": 3580
    },
    {
      "epoch": 16.035684415946474,
      "grad_norm": 14.316969871520996,
      "learning_rate": 4.295074011162339e-06,
      "loss": 6.6841,
      "step": 3600
    },
    {
      "epoch": 16.035684415946474,
      "eval_loss": 0.8470413684844971,
      "eval_runtime": 73.4683,
      "eval_samples_per_second": 1.606,
      "eval_steps_per_second": 0.204,
      "step": 3600
    },
    {
      "epoch": 16.124895455812656,
      "grad_norm": 14.306646347045898,
      "learning_rate": 4.198010191701043e-06,
      "loss": 6.8746,
      "step": 3620
    },
    {
      "epoch": 16.21410649567884,
      "grad_norm": 14.659383773803711,
      "learning_rate": 4.100946372239748e-06,
      "loss": 6.9021,
      "step": 3640
    },
    {
      "epoch": 16.303317535545023,
      "grad_norm": 13.475273132324219,
      "learning_rate": 4.003882552778452e-06,
      "loss": 6.9482,
      "step": 3660
    },
    {
      "epoch": 16.392528575411205,
      "grad_norm": 14.164944648742676,
      "learning_rate": 3.906818733317157e-06,
      "loss": 6.9045,
      "step": 3680
    },
    {
      "epoch": 16.48173961527739,
      "grad_norm": 14.734825134277344,
      "learning_rate": 3.8097549138558605e-06,
      "loss": 6.9192,
      "step": 3700
    },
    {
      "epoch": 16.570950655143573,
      "grad_norm": 14.13365364074707,
      "learning_rate": 3.712691094394565e-06,
      "loss": 6.946,
      "step": 3720
    },
    {
      "epoch": 16.66016169500976,
      "grad_norm": 14.571871757507324,
      "learning_rate": 3.6156272749332687e-06,
      "loss": 6.9395,
      "step": 3740
    },
    {
      "epoch": 16.74937273487594,
      "grad_norm": 14.584409713745117,
      "learning_rate": 3.5185634554719733e-06,
      "loss": 6.9338,
      "step": 3760
    },
    {
      "epoch": 16.838583774742123,
      "grad_norm": 13.741114616394043,
      "learning_rate": 3.4214996360106774e-06,
      "loss": 7.0201,
      "step": 3780
    },
    {
      "epoch": 16.92779481460831,
      "grad_norm": 14.667049407958984,
      "learning_rate": 3.3244358165493815e-06,
      "loss": 6.8804,
      "step": 3800
    },
    {
      "epoch": 16.92779481460831,
      "eval_loss": 0.8465842008590698,
      "eval_runtime": 72.7798,
      "eval_samples_per_second": 1.621,
      "eval_steps_per_second": 0.206,
      "step": 3800
    },
    {
      "epoch": 17.013381655979927,
      "grad_norm": 14.321972846984863,
      "learning_rate": 3.2273719970880857e-06,
      "loss": 6.6723,
      "step": 3820
    },
    {
      "epoch": 17.10259269584611,
      "grad_norm": 14.416158676147461,
      "learning_rate": 3.13030817762679e-06,
      "loss": 6.8937,
      "step": 3840
    },
    {
      "epoch": 17.191803735712295,
      "grad_norm": 13.877206802368164,
      "learning_rate": 3.033244358165494e-06,
      "loss": 6.8528,
      "step": 3860
    },
    {
      "epoch": 17.281014775578477,
      "grad_norm": 14.432390213012695,
      "learning_rate": 2.936180538704198e-06,
      "loss": 6.9181,
      "step": 3880
    },
    {
      "epoch": 17.370225815444662,
      "grad_norm": 14.970827102661133,
      "learning_rate": 2.8391167192429026e-06,
      "loss": 6.8826,
      "step": 3900
    },
    {
      "epoch": 17.459436855310845,
      "grad_norm": 14.511993408203125,
      "learning_rate": 2.7420528997816063e-06,
      "loss": 6.8904,
      "step": 3920
    },
    {
      "epoch": 17.548647895177027,
      "grad_norm": 15.804637908935547,
      "learning_rate": 2.644989080320311e-06,
      "loss": 6.9108,
      "step": 3940
    },
    {
      "epoch": 17.637858935043212,
      "grad_norm": 14.746931076049805,
      "learning_rate": 2.547925260859015e-06,
      "loss": 6.9086,
      "step": 3960
    },
    {
      "epoch": 17.727069974909394,
      "grad_norm": 14.266071319580078,
      "learning_rate": 2.450861441397719e-06,
      "loss": 6.9466,
      "step": 3980
    },
    {
      "epoch": 17.81628101477558,
      "grad_norm": 14.033920288085938,
      "learning_rate": 2.3537976219364233e-06,
      "loss": 6.9029,
      "step": 4000
    },
    {
      "epoch": 17.81628101477558,
      "eval_loss": 0.8448465466499329,
      "eval_runtime": 72.7356,
      "eval_samples_per_second": 1.622,
      "eval_steps_per_second": 0.206,
      "step": 4000
    },
    {
      "epoch": 17.945637022581543,
      "grad_norm": 14.660761833190918,
      "learning_rate": 2.2567338024751274e-06,
      "loss": 6.768,
      "step": 4020
    },
    {
      "epoch": 18.035684415946474,
      "grad_norm": 14.79458999633789,
      "learning_rate": 2.159669983013832e-06,
      "loss": 6.8893,
      "step": 4040
    },
    {
      "epoch": 18.124895455812656,
      "grad_norm": 14.735459327697754,
      "learning_rate": 2.062606163552536e-06,
      "loss": 6.8954,
      "step": 4060
    },
    {
      "epoch": 18.21410649567884,
      "grad_norm": 15.265645027160645,
      "learning_rate": 1.96554234409124e-06,
      "loss": 6.8768,
      "step": 4080
    },
    {
      "epoch": 18.303317535545023,
      "grad_norm": 15.151322364807129,
      "learning_rate": 1.8684785246299445e-06,
      "loss": 6.8775,
      "step": 4100
    },
    {
      "epoch": 18.392528575411205,
      "grad_norm": 14.652266502380371,
      "learning_rate": 1.7714147051686487e-06,
      "loss": 6.8635,
      "step": 4120
    },
    {
      "epoch": 18.48173961527739,
      "grad_norm": 14.277180671691895,
      "learning_rate": 1.6743508857073526e-06,
      "loss": 6.8511,
      "step": 4140
    },
    {
      "epoch": 18.570950655143573,
      "grad_norm": 14.726412773132324,
      "learning_rate": 1.5772870662460567e-06,
      "loss": 6.8758,
      "step": 4160
    },
    {
      "epoch": 18.66016169500976,
      "grad_norm": 14.327113151550293,
      "learning_rate": 1.480223246784761e-06,
      "loss": 6.8878,
      "step": 4180
    },
    {
      "epoch": 18.74937273487594,
      "grad_norm": 14.676918029785156,
      "learning_rate": 1.3831594273234652e-06,
      "loss": 6.8911,
      "step": 4200
    },
    {
      "epoch": 18.74937273487594,
      "eval_loss": 0.852697491645813,
      "eval_runtime": 66.7325,
      "eval_samples_per_second": 1.768,
      "eval_steps_per_second": 0.225,
      "step": 4200
    },
    {
      "epoch": 18.838583774742123,
      "grad_norm": 14.924735069274902,
      "learning_rate": 1.2860956078621695e-06,
      "loss": 6.8355,
      "step": 4220
    },
    {
      "epoch": 18.92779481460831,
      "grad_norm": 14.497506141662598,
      "learning_rate": 1.1890317884008737e-06,
      "loss": 6.8868,
      "step": 4240
    },
    {
      "epoch": 19.013381655979927,
      "grad_norm": 14.609482765197754,
      "learning_rate": 1.0919679689395778e-06,
      "loss": 6.49,
      "step": 4260
    },
    {
      "epoch": 19.10259269584611,
      "grad_norm": 15.467392921447754,
      "learning_rate": 9.94904149478282e-07,
      "loss": 6.9034,
      "step": 4280
    },
    {
      "epoch": 19.191803735712295,
      "grad_norm": 15.162019729614258,
      "learning_rate": 8.978403300169862e-07,
      "loss": 6.8945,
      "step": 4300
    },
    {
      "epoch": 19.281014775578477,
      "grad_norm": 14.755754470825195,
      "learning_rate": 8.007765105556904e-07,
      "loss": 6.8968,
      "step": 4320
    },
    {
      "epoch": 19.370225815444662,
      "grad_norm": 14.468995094299316,
      "learning_rate": 7.037126910943946e-07,
      "loss": 6.7974,
      "step": 4340
    },
    {
      "epoch": 19.459436855310845,
      "grad_norm": 14.247746467590332,
      "learning_rate": 6.066488716330988e-07,
      "loss": 6.8813,
      "step": 4360
    },
    {
      "epoch": 19.548647895177027,
      "grad_norm": 14.490636825561523,
      "learning_rate": 5.09585052171803e-07,
      "loss": 6.7703,
      "step": 4380
    },
    {
      "epoch": 19.637858935043212,
      "grad_norm": 15.670652389526367,
      "learning_rate": 4.1252123271050724e-07,
      "loss": 6.8524,
      "step": 4400
    },
    {
      "epoch": 19.637858935043212,
      "eval_loss": 0.8566910624504089,
      "eval_runtime": 63.9835,
      "eval_samples_per_second": 1.844,
      "eval_steps_per_second": 0.234,
      "step": 4400
    },
    {
      "epoch": 19.727069974909394,
      "grad_norm": 14.26347827911377,
      "learning_rate": 3.1545741324921137e-07,
      "loss": 6.805,
      "step": 4420
    },
    {
      "epoch": 19.81628101477558,
      "grad_norm": 14.780261039733887,
      "learning_rate": 2.1839359378791558e-07,
      "loss": 6.7827,
      "step": 4440
    },
    {
      "epoch": 19.905492054641762,
      "grad_norm": 14.53621768951416,
      "learning_rate": 1.2132977432661976e-07,
      "loss": 6.9384,
      "step": 4460
    },
    {
      "epoch": 19.994703094507944,
      "grad_norm": 14.113224029541016,
      "learning_rate": 2.4265954865323954e-08,
      "loss": 6.7642,
      "step": 4480
    }
  ],
  "logging_steps": 20,
  "max_steps": 4480,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4216512445035315e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
